{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGsKHZcjXxa8",
        "outputId": "42c1ab79-f54f-4ec2-b85f-4bc3bcc69023"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5y5_XDIYXE4",
        "outputId": "2c1fc4e8-59a5-44d0-a993-fdac90ae66aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting manipulation\n",
            "  Downloading manipulation-2022.12.4-py3-none-any.whl (610 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m610.2/610.2 KB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from manipulation) (2.2.1)\n",
            "Collecting gradescope-utils>=0.4.0\n",
            "  Downloading gradescope_utils-0.5.0-py2.py3-none-any.whl (7.1 kB)\n",
            "Collecting timeout-decorator>=0.4.1\n",
            "  Downloading timeout-decorator-0.5.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mpld3>=0.5.1\n",
            "  Downloading mpld3-0.5.9-py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.2/201.2 KB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting drake>=1.10.0\n",
            "  Downloading drake-1.14.0-cp39-cp39-manylinux_2_31_x86_64.whl (91.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from drake>=1.10.0->manipulation) (3.7.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from drake>=1.10.0->manipulation) (6.0)\n",
            "Collecting meshcat\n",
            "  Downloading meshcat-0.3.2-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydot in /usr/local/lib/python3.9/dist-packages (from drake>=1.10.0->manipulation) (1.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from drake>=1.10.0->manipulation) (1.22.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from mpld3>=0.5.1->manipulation) (3.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->mpld3>=0.5.1->manipulation) (2.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->drake>=1.10.0->manipulation) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->drake>=1.10.0->manipulation) (1.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->drake>=1.10.0->manipulation) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->drake>=1.10.0->manipulation) (8.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->drake>=1.10.0->manipulation) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->drake>=1.10.0->manipulation) (23.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->drake>=1.10.0->manipulation) (5.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->drake>=1.10.0->manipulation) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->drake>=1.10.0->manipulation) (4.39.2)\n",
            "Requirement already satisfied: tornado>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from meshcat->drake>=1.10.0->manipulation) (6.2)\n",
            "Collecting pyngrok>=4.1.6\n",
            "  Downloading pyngrok-5.2.1.tar.gz (761 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m761.3/761.3 KB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyzmq>=17.0.0 in /usr/local/lib/python3.9/dist-packages (from meshcat->drake>=1.10.0->manipulation) (23.2.1)\n",
            "Collecting u-msgpack-python>=2.4.1\n",
            "  Downloading u_msgpack_python-2.7.2-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: ipython>=5 in /usr/local/lib/python3.9/dist-packages (from meshcat->drake>=1.10.0->manipulation) (7.9.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->drake>=1.10.0->manipulation) (3.15.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython>=5->meshcat->drake>=1.10.0->manipulation) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython>=5->meshcat->drake>=1.10.0->manipulation) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython>=5->meshcat->drake>=1.10.0->manipulation) (2.0.10)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython>=5->meshcat->drake>=1.10.0->manipulation) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython>=5->meshcat->drake>=1.10.0->manipulation) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.9/dist-packages (from ipython>=5->meshcat->drake>=1.10.0->manipulation) (4.8.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipython>=5->meshcat->drake>=1.10.0->manipulation) (5.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.9/dist-packages (from ipython>=5->meshcat->drake>=1.10.0->manipulation) (67.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->drake>=1.10.0->manipulation) (1.16.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.10->ipython>=5->meshcat->drake>=1.10.0->manipulation) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5->meshcat->drake>=1.10.0->manipulation) (0.2.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect->ipython>=5->meshcat->drake>=1.10.0->manipulation) (0.7.0)\n",
            "Building wheels for collected packages: timeout-decorator, pyngrok\n",
            "  Building wheel for timeout-decorator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for timeout-decorator: filename=timeout_decorator-0.5.0-py3-none-any.whl size=5026 sha256=2af6a2ca7fede7428d38adf2d17ee3c544ccbac5c3da8a29244323d62c60e71d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/45/1d/a7d2bf8dfbdecd78983a3d422f2fe860316cfbae3f3b001ea5\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.2.1-py3-none-any.whl size=19790 sha256=643f103d4c5ca26c7fde46d0853b561f72deb48f51d55096775cbfbe61f9c917\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/89/59/49d4249e00957e94813ac136a335d10ed2e09a856c5096f95c\n",
            "Successfully built timeout-decorator pyngrok\n",
            "Installing collected packages: u-msgpack-python, timeout-decorator, gradescope-utils, pyngrok, jedi, mpld3, meshcat, drake, manipulation\n",
            "Successfully installed drake-1.14.0 gradescope-utils-0.5.0 jedi-0.18.2 manipulation-2022.12.4 meshcat-0.3.2 mpld3-0.5.9 pyngrok-5.2.1 timeout-decorator-0.5.0 u-msgpack-python-2.7.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.9/dist-packages (0.29.33)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-_d2bi1aa\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-_d2bi1aa\n",
            "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.9/dist-packages (from pycocotools==2.0) (67.6.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.9/dist-packages (from pycocotools==2.0) (0.29.33)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from pycocotools==2.0) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (23.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (8.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.4)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (5.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (4.39.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=2.1.0->pycocotools==2.0) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0) (1.16.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp39-cp39-linux_x86_64.whl size=397893 sha256=8b5fc5e6dbd55a215f766defd4e3ba7233670b7e74d741c82fe60cd3d606988e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_j3bdqo_/wheels/13/c1/d6/a321055f7089f1a6af654fbf794536b196999f082a9cb68a37\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.6\n",
            "    Uninstalling pycocotools-2.0.6:\n",
            "      Successfully uninstalled pycocotools-2.0.6\n",
            "Successfully installed pycocotools-2.0\n",
            "Cloning into 'vision'...\n",
            "remote: Enumerating objects: 321529, done.\u001b[K\n",
            "remote: Counting objects: 100% (4551/4551), done.\u001b[K\n",
            "remote: Compressing objects: 100% (383/383), done.\u001b[K\n",
            "remote: Total 321529 (delta 4299), reused 4396 (delta 4159), pack-reused 316978\u001b[K\n",
            "Receiving objects: 100% (321529/321529), 651.55 MiB | 18.51 MiB/s, done.\n",
            "Resolving deltas: 100% (295651/295651), done.\n",
            "Note: switching to 'v0.3.0'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at be376084d8 version check against PyTorch's CUDA version\n"
          ]
        }
      ],
      "source": [
        "# Intsall packages\n",
        "\n",
        "# Drake\n",
        "!pip install manipulation\n",
        "# C-Extentions\n",
        "!pip install cython  \n",
        "# Pycocotools\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "\n",
        "\n",
        "# Clone TorchVision references/detection\n",
        "!git clone https://github.com/pytorch/vision.git\n",
        "!cd vision && git checkout v0.3.0\n",
        "!cp vision/references/detection/utils.py ./\n",
        "!cp vision/references/detection/transforms.py ./\n",
        "!cp vision/references/detection/coco_eval.py ./\n",
        "!cp vision/references/detection/engine.py ./\n",
        "!cp vision/references/detection/coco_utils.py ./\n",
        "\n",
        "from manipulation import running_as_notebook\n",
        "\n",
        "# Import modules\n",
        "import fnmatch\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import multiprocessing\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "import torch\n",
        "import torch.utils.data\n",
        "\n",
        "# 0: Red\n",
        "# 1: Blue\n",
        "# 2: Green\n",
        "# 3: Yellow\n",
        "# 4: Magenta\n",
        "\n",
        "ycb = [0, 1, 2, 3, 4]\n",
        "\n",
        "#drake_reserved_labels = [32765, 32764, 32766, 32767]\n",
        "\n",
        "def colorize_labels(image):\n",
        "    \"\"\"Colorizes labels.\"\"\"\n",
        "    cc = mpl.colors.ColorConverter()\n",
        "    color_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
        "    colors = np.array([cc.to_rgb(c[\"color\"]) for c in color_cycle])\n",
        "    bg_color = [0, 0, 0]\n",
        "    image = np.squeeze(image)\n",
        "    background = np.zeros(image.shape[:2], dtype=bool)\n",
        "    for label in reserved_labels:\n",
        "        background |= image == int(label)\n",
        "    foreground = image[np.logical_not(background)]\n",
        "    color_image = colors[image % len(colors)]\n",
        "    color_image[background] = bg_color\n",
        "    return color_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nlFh8WDuYyqU"
      },
      "outputs": [],
      "source": [
        "# Unzip dataset\n",
        "\n",
        "dataset_path = \"box_maskrcnn_data_2\"\n",
        "if not os.path.exists(dataset_path):\n",
        "  !cp /content/drive/MyDrive/box_maskrcnn_data_2.zip ./\n",
        "  !unzip -q box_maskrcnn_data_2.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HCV09neuY8Wy"
      },
      "outputs": [],
      "source": [
        "# Dataset class definition\n",
        "\n",
        "class BinPickingDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transforms=None):\n",
        "        self.root = root\n",
        "        self.num_images = len(fnmatch.filter(os.listdir(root),'*.png'))\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename_base = os.path.join(self.root, f\"{idx:05d}\")\n",
        "\n",
        "        img = Image.open(filename_base + \".png\").convert(\"RGB\")\n",
        "        mask = np.squeeze(np.load(filename_base + \"_mask.npy\"))\n",
        "\n",
        "        with open(filename_base + \".json\", \"r\") as f:\n",
        "            instance_id_to_class_name = json.load(f)\n",
        "        labels = ycb == instance_id_to_class_name\n",
        "\n",
        "        # instances are encoded as different colors\n",
        "        obj_ids = np.asarray(list(instance_id_to_class_name.keys()))\n",
        "        count = (mask == np.int16(obj_ids)[:, None, None]).sum(axis=2).sum(axis=1)\n",
        "        \n",
        "        # discard objects instances with less than 10 pixels\n",
        "        obj_ids = obj_ids[count >= 10]\n",
        "        \n",
        "        labels = [ycb.index(instance_id_to_class_name[id]) for id in obj_ids]\n",
        "        obj_ids = np.int16(np.asarray(obj_ids))\n",
        "\n",
        "        # split the color-encoded mask into a set of binary masks\n",
        "        masks = mask == obj_ids[:, None, None]\n",
        "\n",
        "        # get bounding box coordinates for each mask\n",
        "        num_objs = len(obj_ids)\n",
        "        boxes = []\n",
        "        for i in range(num_objs):\n",
        "            pos = np.where(masks[i])\n",
        "            xmin = np.min(pos[1])\n",
        "            xmax = np.max(pos[1])\n",
        "            ymin = np.min(pos[0])\n",
        "            ymax = np.max(pos[0])\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
        "\n",
        "        image_id = torch.tensor([idx])\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "        # suppose all instances are not crowd\n",
        "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"masks\"] = masks\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img, target = self.transforms(img, target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AFOrtUCoZDcV"
      },
      "outputs": [],
      "source": [
        "# Check the dataset output\n",
        "\n",
        "dataset = BinPickingDataset(dataset_path)\n",
        "single = True\n",
        "if single:\n",
        "  dataset[0][0]\n",
        "else:\n",
        "  for i in range(len(dataset)):\n",
        "    dataset[i][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YrMOwxEye65c"
      },
      "outputs": [],
      "source": [
        "# Define the network\n",
        "\n",
        "# Import torchvision\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.models.detection import MaskRCNN_ResNet50_FPN_Weights\n",
        "\n",
        "      \n",
        "def get_instance_segmentation_model(num_classes):\n",
        "    # load an instance segmentation model pre-trained on COCO\n",
        "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(\n",
        "        weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
        "\n",
        "    # get the number of input features for the classifier\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    # replace the pre-trained head with a new one\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    # now get the number of input features for the mask classifier\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 256\n",
        "    # and replace the mask predictor with a new one\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
        "                                                       hidden_layer,\n",
        "                                                       num_classes)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "47ABgAF4fwqa"
      },
      "outputs": [],
      "source": [
        "# Helper function for data augmentation and transformation\n",
        "\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import transforms as T\n",
        "\n",
        "def get_transform(train):\n",
        "    transforms = []\n",
        "    # converts the image, a PIL image, into a PyTorch Tensor\n",
        "    transforms.append(T.ToTensor())\n",
        "    if train:\n",
        "        # during training, randomly flip the training images\n",
        "        # and ground-truth for data augmentation\n",
        "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "    return T.Compose(transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZD4p9lggM88",
        "outputId": "9d72e69a-e173-467a-bd40-663d4d8f83de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the dataset and separate\n",
        "\n",
        "# use our dataset and defined transformations\n",
        "dataset = BinPickingDataset(dataset_path, get_transform(train=True))\n",
        "dataset_test = BinPickingDataset(dataset_path, get_transform(train=False))\n",
        "\n",
        "# split the dataset in train and test set\n",
        "torch.manual_seed(1)\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
        "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
        "\n",
        "# define training and validation data loaders\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=2, shuffle=True, num_workers=4,\n",
        "    collate_fn=utils.collate_fn)\n",
        "\n",
        "data_loader_test = torch.utils.data.DataLoader(\n",
        "    dataset_test, batch_size=1, shuffle=False, num_workers=4,\n",
        "    collate_fn=utils.collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "bf34de56443b4789b9555e98e8b1d901",
            "71431459ca2b454bad1190da73ddc880",
            "5277f085a2b9429e8bcc49cb06ce4e98",
            "cbc6c45bcf024c6b8f16f0e70aecf854",
            "3ff958a1c9a04558b6be01c6561bac80",
            "d6ea50af33f14f0e89d067a097a71a74",
            "34a62493ef564424ba1e3bce171254d2",
            "a92c7bda8eeb4ceb9499934a35964387",
            "175c5bd2b7424c73a73a29d2b3a0ad25",
            "1a86dec2a02848de9ff2992a737770fd",
            "168a34af1cc9422e99cb44da3640746c"
          ]
        },
        "id": "03ReDHCGgkvN",
        "outputId": "e4067dd0-8e28-49e9-da45-f4583c6695c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/170M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf34de56443b4789b9555e98e8b1d901"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Instantiate the model and optimizer\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "num_classes = len(ycb) + 1\n",
        "\n",
        "# get the model using our helper function\n",
        "model = get_instance_segmentation_model(num_classes)\n",
        "# move model to the right device\n",
        "model.to(device)\n",
        "\n",
        "# construct an optimizer\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005,\n",
        "                            momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "# and a learning rate scheduler which decreases the learning rate by\n",
        "# 10x every 3 epochs\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                               step_size=3,\n",
        "                                               gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cp6-0IHnl_2z"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, List, Dict, Optional\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from collections import OrderedDict\n",
        "from torchvision.models.detection.roi_heads import fastrcnn_loss\n",
        "from torchvision.models.detection.rpn import concat_box_prediction_layers\n",
        "def eval_forward(model, images, targets):\n",
        "    # type: (List[Tensor], Optional[List[Dict[str, Tensor]]]) -> Tuple[Dict[str, Tensor], List[Dict[str, Tensor]]]\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        images (list[Tensor]): images to be processed\n",
        "        targets (list[Dict[str, Tensor]]): ground-truth boxes present in the image (optional)\n",
        "    Returns:\n",
        "        result (list[BoxList] or dict[Tensor]): the output from the model.\n",
        "            It returns list[BoxList] contains additional fields\n",
        "            like `scores`, `labels` and `mask` (for Mask R-CNN models).\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    original_image_sizes: List[Tuple[int, int]] = []\n",
        "    for img in images:\n",
        "        val = img.shape[-2:]\n",
        "        assert len(val) == 2\n",
        "        original_image_sizes.append((val[0], val[1]))\n",
        "\n",
        "    images, targets = model.transform(images, targets)\n",
        "\n",
        "    # Check for degenerate boxes\n",
        "    # TODO: Move this to a function\n",
        "    if targets is not None:\n",
        "        for target_idx, target in enumerate(targets):\n",
        "            boxes = target[\"boxes\"]\n",
        "            degenerate_boxes = boxes[:, 2:] <= boxes[:, :2]\n",
        "            if degenerate_boxes.any():\n",
        "                # print the first degenerate box\n",
        "                bb_idx = torch.where(degenerate_boxes.any(dim=1))[0][0]\n",
        "                degen_bb: List[float] = boxes[bb_idx].tolist()\n",
        "                raise ValueError(\n",
        "                    \"All bounding boxes should have positive height and width.\"\n",
        "                    f\" Found invalid box {degen_bb} for target at index {target_idx}.\"\n",
        "                )\n",
        "\n",
        "    features = model.backbone(images.tensors)\n",
        "    if isinstance(features, torch.Tensor):\n",
        "        features = OrderedDict([(\"0\", features)])\n",
        "    model.rpn.training=True\n",
        "    # model.roi_heads.training=True\n",
        "\n",
        "\n",
        "    # proposals, proposal_losses = model.rpn(images, features, targets)\n",
        "    features_rpn = list(features.values())\n",
        "    objectness, pred_bbox_deltas = model.rpn.head(features_rpn)\n",
        "    anchors = model.rpn.anchor_generator(images, features_rpn)\n",
        "\n",
        "    num_images = len(anchors)\n",
        "    num_anchors_per_level_shape_tensors = [o[0].shape for o in objectness]\n",
        "    num_anchors_per_level = [s[0] * s[1] * s[2] for s in num_anchors_per_level_shape_tensors]\n",
        "    objectness, pred_bbox_deltas = concat_box_prediction_layers(objectness, pred_bbox_deltas)\n",
        "    # apply pred_bbox_deltas to anchors to obtain the decoded proposals\n",
        "    # note that we detach the deltas because Faster R-CNN do not backprop through\n",
        "    # the proposals\n",
        "    proposals = model.rpn.box_coder.decode(pred_bbox_deltas.detach(), anchors)\n",
        "    proposals = proposals.view(num_images, -1, 4)\n",
        "    proposals, scores = model.rpn.filter_proposals(proposals, objectness, images.image_sizes, num_anchors_per_level)\n",
        "\n",
        "    proposal_losses = {}\n",
        "    assert targets is not None\n",
        "    labels, matched_gt_boxes = model.rpn.assign_targets_to_anchors(anchors, targets)\n",
        "    regression_targets = model.rpn.box_coder.encode(matched_gt_boxes, anchors)\n",
        "    loss_objectness, loss_rpn_box_reg = model.rpn.compute_loss(\n",
        "        objectness, pred_bbox_deltas, labels, regression_targets\n",
        "    )\n",
        "    proposal_losses = {\n",
        "        \"loss_objectness\": loss_objectness,\n",
        "        \"loss_rpn_box_reg\": loss_rpn_box_reg,\n",
        "    }\n",
        "\n",
        "    # detections, detector_losses = model.roi_heads(features, proposals, images.image_sizes, targets)\n",
        "    image_shapes = images.image_sizes\n",
        "    proposals, matched_idxs, labels, regression_targets = model.roi_heads.select_training_samples(proposals, targets)\n",
        "    box_features = model.roi_heads.box_roi_pool(features, proposals, image_shapes)\n",
        "    box_features = model.roi_heads.box_head(box_features)\n",
        "    class_logits, box_regression = model.roi_heads.box_predictor(box_features)\n",
        "\n",
        "    result: List[Dict[str, torch.Tensor]] = []\n",
        "    detector_losses = {}\n",
        "    loss_classifier, loss_box_reg = fastrcnn_loss(class_logits, box_regression, labels, regression_targets)\n",
        "    detector_losses = {\"loss_classifier\": loss_classifier, \"loss_box_reg\": loss_box_reg}\n",
        "    boxes, scores, labels = model.roi_heads.postprocess_detections(class_logits, box_regression, proposals, image_shapes)\n",
        "    num_images = len(boxes)\n",
        "    for i in range(num_images):\n",
        "        result.append(\n",
        "            {\n",
        "                \"boxes\": boxes[i],\n",
        "                \"labels\": labels[i],\n",
        "                \"scores\": scores[i],\n",
        "            }\n",
        "        )\n",
        "    detections = result\n",
        "    detections = model.transform.postprocess(detections, images.image_sizes, original_image_sizes)  # type: ignore[operator]\n",
        "    model.rpn.training=False\n",
        "    model.roi_heads.training=False\n",
        "    losses = {}\n",
        "    losses.update(detector_losses)\n",
        "    losses.update(proposal_losses)\n",
        "    return losses, detections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fFEYc7BF_q5"
      },
      "outputs": [],
      "source": [
        "def evaluate_loss(model, data_loader, device):\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "      for images, targets in data_loader:\n",
        "          images = list(image.to(device) for image in images)\n",
        "          targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "          losses_dict, detections = eval_forward(model, images, targets)\n",
        "         \n",
        "          losses = sum(loss for loss in losses_dict.values())\n",
        "\n",
        "          val_loss += losses\n",
        "          \n",
        "    validation_loss = val_loss/ len(data_loader)    \n",
        "    return validation_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XuhJw4FhYWc",
        "outputId": "b0afa6a6-47f4-4865-e95e-e33936e72b6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0]  [  0/385]  eta: 0:53:19  lr: 0.000018  loss: 5.3855 (5.3855)  loss_classifier: 2.0118 (2.0118)  loss_box_reg: 0.2553 (0.2553)  loss_mask: 2.3035 (2.3035)  loss_objectness: 0.7735 (0.7735)  loss_rpn_box_reg: 0.0414 (0.0414)  time: 8.3098  data: 0.3962  max mem: 2142\n",
            "Epoch: [0]  [ 10/385]  eta: 0:07:41  lr: 0.000148  loss: 4.9957 (4.8005)  loss_classifier: 1.7376 (1.6312)  loss_box_reg: 0.4042 (0.4039)  loss_mask: 1.7847 (1.8203)  loss_objectness: 0.7735 (0.8931)  loss_rpn_box_reg: 0.0446 (0.0519)  time: 1.2295  data: 0.0458  max mem: 2420\n",
            "Epoch: [0]  [ 20/385]  eta: 0:05:34  lr: 0.000278  loss: 3.1584 (3.8540)  loss_classifier: 0.8781 (1.2309)  loss_box_reg: 0.5677 (0.5464)  loss_mask: 1.3632 (1.4300)  loss_objectness: 0.4966 (0.5971)  loss_rpn_box_reg: 0.0422 (0.0495)  time: 0.5460  data: 0.0126  max mem: 2643\n",
            "Epoch: [0]  [ 30/385]  eta: 0:04:46  lr: 0.000408  loss: 2.5083 (3.3537)  loss_classifier: 0.7729 (1.0672)  loss_box_reg: 0.7484 (0.6116)  loss_mask: 0.7513 (1.1954)  loss_objectness: 0.0991 (0.4363)  loss_rpn_box_reg: 0.0348 (0.0432)  time: 0.5755  data: 0.0125  max mem: 2644\n",
            "Epoch: [0]  [ 40/385]  eta: 0:04:19  lr: 0.000538  loss: 2.2439 (3.0866)  loss_classifier: 0.7219 (0.9844)  loss_box_reg: 0.7551 (0.6515)  loss_mask: 0.6837 (1.0701)  loss_objectness: 0.0635 (0.3414)  loss_rpn_box_reg: 0.0277 (0.0392)  time: 0.5818  data: 0.0108  max mem: 2644\n",
            "Epoch: [0]  [ 50/385]  eta: 0:04:02  lr: 0.000668  loss: 2.2463 (2.9138)  loss_classifier: 0.7219 (0.9275)  loss_box_reg: 0.7738 (0.6814)  loss_mask: 0.6639 (0.9901)  loss_objectness: 0.0258 (0.2788)  loss_rpn_box_reg: 0.0261 (0.0361)  time: 0.5915  data: 0.0132  max mem: 2645\n",
            "Epoch: [0]  [ 60/385]  eta: 0:03:47  lr: 0.000798  loss: 2.2532 (2.7926)  loss_classifier: 0.7075 (0.8876)  loss_box_reg: 0.8480 (0.6987)  loss_mask: 0.6516 (0.9322)  loss_objectness: 0.0252 (0.2397)  loss_rpn_box_reg: 0.0253 (0.0344)  time: 0.5947  data: 0.0132  max mem: 2645\n",
            "Epoch: [0]  [ 70/385]  eta: 0:03:36  lr: 0.000929  loss: 2.1479 (2.7004)  loss_classifier: 0.6639 (0.8577)  loss_box_reg: 0.8234 (0.7105)  loss_mask: 0.6305 (0.8896)  loss_objectness: 0.0310 (0.2103)  loss_rpn_box_reg: 0.0221 (0.0323)  time: 0.5984  data: 0.0136  max mem: 2645\n",
            "Epoch: [0]  [ 80/385]  eta: 0:03:26  lr: 0.001059  loss: 2.2156 (2.6371)  loss_classifier: 0.7069 (0.8380)  loss_box_reg: 0.8396 (0.7276)  loss_mask: 0.6057 (0.8516)  loss_objectness: 0.0282 (0.1890)  loss_rpn_box_reg: 0.0195 (0.0310)  time: 0.6074  data: 0.0136  max mem: 2645\n",
            "Epoch: [0]  [ 90/385]  eta: 0:03:17  lr: 0.001189  loss: 2.1362 (2.5751)  loss_classifier: 0.6609 (0.8185)  loss_box_reg: 0.8096 (0.7321)  loss_mask: 0.5900 (0.8233)  loss_objectness: 0.0217 (0.1713)  loss_rpn_box_reg: 0.0215 (0.0299)  time: 0.6084  data: 0.0124  max mem: 2645\n",
            "Epoch: [0]  [100/385]  eta: 0:03:09  lr: 0.001319  loss: 2.0807 (2.5149)  loss_classifier: 0.6576 (0.7989)  loss_box_reg: 0.7903 (0.7333)  loss_mask: 0.5697 (0.7963)  loss_objectness: 0.0226 (0.1573)  loss_rpn_box_reg: 0.0202 (0.0290)  time: 0.6102  data: 0.0143  max mem: 2645\n",
            "Epoch: [0]  [110/385]  eta: 0:03:01  lr: 0.001449  loss: 2.0540 (2.4698)  loss_classifier: 0.6461 (0.7841)  loss_box_reg: 0.7787 (0.7359)  loss_mask: 0.5541 (0.7760)  loss_objectness: 0.0226 (0.1456)  loss_rpn_box_reg: 0.0185 (0.0282)  time: 0.6127  data: 0.0137  max mem: 2645\n",
            "Epoch: [0]  [120/385]  eta: 0:02:54  lr: 0.001579  loss: 1.9869 (2.4237)  loss_classifier: 0.6441 (0.7694)  loss_box_reg: 0.7431 (0.7342)  loss_mask: 0.5513 (0.7567)  loss_objectness: 0.0200 (0.1358)  loss_rpn_box_reg: 0.0179 (0.0275)  time: 0.6171  data: 0.0139  max mem: 2645\n",
            "Epoch: [0]  [130/385]  eta: 0:02:46  lr: 0.001709  loss: 1.9189 (2.3846)  loss_classifier: 0.5793 (0.7555)  loss_box_reg: 0.7490 (0.7344)  loss_mask: 0.5324 (0.7397)  loss_objectness: 0.0229 (0.1278)  loss_rpn_box_reg: 0.0214 (0.0272)  time: 0.6204  data: 0.0127  max mem: 2645\n",
            "Epoch: [0]  [140/385]  eta: 0:02:39  lr: 0.001839  loss: 1.8253 (2.3422)  loss_classifier: 0.5622 (0.7395)  loss_box_reg: 0.7316 (0.7302)  loss_mask: 0.5324 (0.7251)  loss_objectness: 0.0229 (0.1208)  loss_rpn_box_reg: 0.0214 (0.0267)  time: 0.6218  data: 0.0118  max mem: 2645\n",
            "Epoch: [0]  [150/385]  eta: 0:02:32  lr: 0.001969  loss: 1.7886 (2.3076)  loss_classifier: 0.5242 (0.7253)  loss_box_reg: 0.7151 (0.7288)  loss_mask: 0.5272 (0.7117)  loss_objectness: 0.0249 (0.1152)  loss_rpn_box_reg: 0.0201 (0.0265)  time: 0.6239  data: 0.0116  max mem: 2645\n",
            "Epoch: [0]  [160/385]  eta: 0:02:26  lr: 0.002099  loss: 1.7816 (2.2715)  loss_classifier: 0.4880 (0.7093)  loss_box_reg: 0.7004 (0.7246)  loss_mask: 0.5204 (0.6998)  loss_objectness: 0.0337 (0.1114)  loss_rpn_box_reg: 0.0202 (0.0263)  time: 0.6308  data: 0.0121  max mem: 2645\n",
            "Epoch: [0]  [170/385]  eta: 0:02:19  lr: 0.002229  loss: 1.7110 (2.2336)  loss_classifier: 0.4471 (0.6924)  loss_box_reg: 0.6711 (0.7193)  loss_mask: 0.5192 (0.6892)  loss_objectness: 0.0312 (0.1066)  loss_rpn_box_reg: 0.0225 (0.0261)  time: 0.6283  data: 0.0125  max mem: 2645\n",
            "Epoch: [0]  [180/385]  eta: 0:02:12  lr: 0.002359  loss: 1.6833 (2.2051)  loss_classifier: 0.4300 (0.6777)  loss_box_reg: 0.6815 (0.7161)  loss_mask: 0.5040 (0.6794)  loss_objectness: 0.0329 (0.1051)  loss_rpn_box_reg: 0.0219 (0.0267)  time: 0.6299  data: 0.0128  max mem: 2645\n",
            "Epoch: [0]  [190/385]  eta: 0:02:06  lr: 0.002489  loss: 1.6934 (2.1793)  loss_classifier: 0.4326 (0.6663)  loss_box_reg: 0.6815 (0.7140)  loss_mask: 0.5035 (0.6711)  loss_objectness: 0.0395 (0.1015)  loss_rpn_box_reg: 0.0183 (0.0263)  time: 0.6359  data: 0.0130  max mem: 2645\n",
            "Epoch: [0]  [200/385]  eta: 0:01:59  lr: 0.002620  loss: 1.6267 (2.1500)  loss_classifier: 0.4104 (0.6527)  loss_box_reg: 0.6512 (0.7097)  loss_mask: 0.5161 (0.6638)  loss_objectness: 0.0275 (0.0978)  loss_rpn_box_reg: 0.0183 (0.0260)  time: 0.6289  data: 0.0118  max mem: 2645\n",
            "Epoch: [0]  [210/385]  eta: 0:01:52  lr: 0.002750  loss: 1.5688 (2.1247)  loss_classifier: 0.3845 (0.6407)  loss_box_reg: 0.6489 (0.7073)  loss_mask: 0.5100 (0.6563)  loss_objectness: 0.0245 (0.0946)  loss_rpn_box_reg: 0.0193 (0.0258)  time: 0.6293  data: 0.0127  max mem: 2645\n",
            "Epoch: [0]  [220/385]  eta: 0:01:46  lr: 0.002880  loss: 1.6249 (2.1009)  loss_classifier: 0.4128 (0.6298)  loss_box_reg: 0.6706 (0.7044)  loss_mask: 0.5163 (0.6498)  loss_objectness: 0.0209 (0.0915)  loss_rpn_box_reg: 0.0198 (0.0255)  time: 0.6280  data: 0.0126  max mem: 2645\n",
            "Epoch: [0]  [230/385]  eta: 0:01:39  lr: 0.003010  loss: 1.5517 (2.0719)  loss_classifier: 0.3470 (0.6162)  loss_box_reg: 0.6338 (0.6991)  loss_mask: 0.4977 (0.6424)  loss_objectness: 0.0234 (0.0890)  loss_rpn_box_reg: 0.0191 (0.0253)  time: 0.6236  data: 0.0132  max mem: 2645\n",
            "Epoch: [0]  [240/385]  eta: 0:01:33  lr: 0.003140  loss: 1.4862 (2.0478)  loss_classifier: 0.3156 (0.6052)  loss_box_reg: 0.5769 (0.6949)  loss_mask: 0.4896 (0.6364)  loss_objectness: 0.0254 (0.0864)  loss_rpn_box_reg: 0.0166 (0.0250)  time: 0.6196  data: 0.0122  max mem: 2645\n",
            "Epoch: [0]  [250/385]  eta: 0:01:26  lr: 0.003270  loss: 1.5881 (2.0303)  loss_classifier: 0.3632 (0.5958)  loss_box_reg: 0.6357 (0.6933)  loss_mask: 0.5093 (0.6318)  loss_objectness: 0.0233 (0.0845)  loss_rpn_box_reg: 0.0166 (0.0249)  time: 0.6229  data: 0.0125  max mem: 2645\n",
            "Epoch: [0]  [260/385]  eta: 0:01:20  lr: 0.003400  loss: 1.5881 (2.0093)  loss_classifier: 0.3613 (0.5855)  loss_box_reg: 0.6442 (0.6896)  loss_mask: 0.5181 (0.6273)  loss_objectness: 0.0261 (0.0824)  loss_rpn_box_reg: 0.0192 (0.0246)  time: 0.6223  data: 0.0128  max mem: 2645\n",
            "Epoch: [0]  [270/385]  eta: 0:01:13  lr: 0.003530  loss: 1.4482 (1.9859)  loss_classifier: 0.3011 (0.5745)  loss_box_reg: 0.5876 (0.6845)  loss_mask: 0.4983 (0.6226)  loss_objectness: 0.0206 (0.0800)  loss_rpn_box_reg: 0.0171 (0.0244)  time: 0.6156  data: 0.0127  max mem: 2645\n",
            "Epoch: [0]  [280/385]  eta: 0:01:07  lr: 0.003660  loss: 1.3646 (1.9663)  loss_classifier: 0.2941 (0.5651)  loss_box_reg: 0.5414 (0.6805)  loss_mask: 0.5084 (0.6186)  loss_objectness: 0.0162 (0.0780)  loss_rpn_box_reg: 0.0170 (0.0242)  time: 0.6153  data: 0.0127  max mem: 2645\n",
            "Epoch: [0]  [290/385]  eta: 0:01:00  lr: 0.003790  loss: 1.4092 (1.9492)  loss_classifier: 0.2979 (0.5562)  loss_box_reg: 0.5867 (0.6778)  loss_mask: 0.5100 (0.6145)  loss_objectness: 0.0225 (0.0765)  loss_rpn_box_reg: 0.0190 (0.0242)  time: 0.6238  data: 0.0124  max mem: 2645\n",
            "Epoch: [0]  [300/385]  eta: 0:00:54  lr: 0.003920  loss: 1.4345 (1.9343)  loss_classifier: 0.3283 (0.5493)  loss_box_reg: 0.5969 (0.6756)  loss_mask: 0.4956 (0.6106)  loss_objectness: 0.0186 (0.0746)  loss_rpn_box_reg: 0.0221 (0.0241)  time: 0.6331  data: 0.0132  max mem: 2645\n",
            "Epoch: [0]  [310/385]  eta: 0:00:47  lr: 0.004050  loss: 1.4193 (1.9165)  loss_classifier: 0.3215 (0.5412)  loss_box_reg: 0.5723 (0.6721)  loss_mask: 0.4768 (0.6065)  loss_objectness: 0.0155 (0.0728)  loss_rpn_box_reg: 0.0157 (0.0239)  time: 0.6302  data: 0.0121  max mem: 2645\n",
            "Epoch: [0]  [320/385]  eta: 0:00:41  lr: 0.004181  loss: 1.3866 (1.9014)  loss_classifier: 0.2949 (0.5337)  loss_box_reg: 0.5487 (0.6695)  loss_mask: 0.4769 (0.6028)  loss_objectness: 0.0154 (0.0717)  loss_rpn_box_reg: 0.0176 (0.0237)  time: 0.6307  data: 0.0128  max mem: 2645\n",
            "Epoch: [0]  [330/385]  eta: 0:00:35  lr: 0.004311  loss: 1.3577 (1.8838)  loss_classifier: 0.2786 (0.5259)  loss_box_reg: 0.5487 (0.6658)  loss_mask: 0.4683 (0.5984)  loss_objectness: 0.0189 (0.0702)  loss_rpn_box_reg: 0.0195 (0.0236)  time: 0.6302  data: 0.0122  max mem: 2645\n",
            "Epoch: [0]  [340/385]  eta: 0:00:28  lr: 0.004441  loss: 1.3119 (1.8676)  loss_classifier: 0.2665 (0.5184)  loss_box_reg: 0.5453 (0.6619)  loss_mask: 0.4727 (0.5952)  loss_objectness: 0.0185 (0.0687)  loss_rpn_box_reg: 0.0166 (0.0234)  time: 0.6269  data: 0.0134  max mem: 2645\n",
            "Epoch: [0]  [350/385]  eta: 0:00:22  lr: 0.004571  loss: 1.2244 (1.8501)  loss_classifier: 0.2369 (0.5103)  loss_box_reg: 0.5505 (0.6581)  loss_mask: 0.4744 (0.5913)  loss_objectness: 0.0140 (0.0671)  loss_rpn_box_reg: 0.0148 (0.0232)  time: 0.6215  data: 0.0132  max mem: 2645\n",
            "Epoch: [0]  [360/385]  eta: 0:00:15  lr: 0.004701  loss: 1.3055 (1.8355)  loss_classifier: 0.2417 (0.5035)  loss_box_reg: 0.5669 (0.6554)  loss_mask: 0.4469 (0.5875)  loss_objectness: 0.0167 (0.0660)  loss_rpn_box_reg: 0.0178 (0.0231)  time: 0.6242  data: 0.0126  max mem: 2645\n",
            "Epoch: [0]  [370/385]  eta: 0:00:09  lr: 0.004831  loss: 1.3214 (1.8216)  loss_classifier: 0.2488 (0.4967)  loss_box_reg: 0.5654 (0.6527)  loss_mask: 0.4469 (0.5844)  loss_objectness: 0.0175 (0.0648)  loss_rpn_box_reg: 0.0191 (0.0230)  time: 0.6262  data: 0.0128  max mem: 2645\n",
            "Epoch: [0]  [380/385]  eta: 0:00:03  lr: 0.004961  loss: 1.3398 (1.8085)  loss_classifier: 0.2580 (0.4906)  loss_box_reg: 0.5556 (0.6501)  loss_mask: 0.4583 (0.5813)  loss_objectness: 0.0155 (0.0636)  loss_rpn_box_reg: 0.0188 (0.0229)  time: 0.6242  data: 0.0114  max mem: 2645\n",
            "Epoch: [0]  [384/385]  eta: 0:00:00  lr: 0.005000  loss: 1.3225 (1.8031)  loss_classifier: 0.2372 (0.4881)  loss_box_reg: 0.5551 (0.6491)  loss_mask: 0.4583 (0.5799)  loss_objectness: 0.0168 (0.0632)  loss_rpn_box_reg: 0.0191 (0.0229)  time: 0.6249  data: 0.0109  max mem: 2645\n",
            "Epoch: [0] Total time: 0:04:04 (0.6359 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/50]  eta: 0:00:33  model_time: 0.2666 (0.2666)  evaluator_time: 0.0876 (0.0876)  time: 0.6792  data: 0.3219  max mem: 2645\n",
            "Test:  [49/50]  eta: 0:00:00  model_time: 0.1574 (0.1757)  evaluator_time: 0.0406 (0.0609)  time: 0.2178  data: 0.0048  max mem: 2645\n",
            "Test: Total time: 0:00:12 (0.2568 s / it)\n",
            "Averaged stats: model_time: 0.1574 (0.1757)  evaluator_time: 0.0406 (0.0609)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.195\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.588\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.058\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.151\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.196\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.137\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.329\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.346\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "IoU metric: segm\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.135\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.479\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.017\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.024\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.137\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.097\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.237\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.253\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.254\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Epoch: [1]  [  0/385]  eta: 0:06:57  lr: 0.005000  loss: 1.1127 (1.1127)  loss_classifier: 0.2011 (0.2011)  loss_box_reg: 0.4411 (0.4411)  loss_mask: 0.4214 (0.4214)  loss_objectness: 0.0296 (0.0296)  loss_rpn_box_reg: 0.0196 (0.0196)  time: 1.0841  data: 0.4456  max mem: 2645\n",
            "Epoch: [1]  [ 10/385]  eta: 0:04:08  lr: 0.005000  loss: 1.2392 (1.2970)  loss_classifier: 0.2583 (0.2697)  loss_box_reg: 0.5058 (0.5289)  loss_mask: 0.4721 (0.4563)  loss_objectness: 0.0204 (0.0219)  loss_rpn_box_reg: 0.0196 (0.0202)  time: 0.6639  data: 0.0495  max mem: 2645\n",
            "Epoch: [1]  [ 20/385]  eta: 0:03:57  lr: 0.005000  loss: 1.2392 (1.3022)  loss_classifier: 0.2543 (0.2658)  loss_box_reg: 0.5250 (0.5410)  loss_mask: 0.4553 (0.4558)  loss_objectness: 0.0162 (0.0212)  loss_rpn_box_reg: 0.0174 (0.0185)  time: 0.6295  data: 0.0107  max mem: 2645\n",
            "Epoch: [1]  [ 30/385]  eta: 0:03:49  lr: 0.005000  loss: 1.2811 (1.2944)  loss_classifier: 0.2549 (0.2637)  loss_box_reg: 0.5497 (0.5360)  loss_mask: 0.4483 (0.4544)  loss_objectness: 0.0167 (0.0220)  loss_rpn_box_reg: 0.0153 (0.0183)  time: 0.6378  data: 0.0115  max mem: 2645\n",
            "Epoch: [1]  [ 40/385]  eta: 0:03:43  lr: 0.005000  loss: 1.3150 (1.3089)  loss_classifier: 0.2648 (0.2643)  loss_box_reg: 0.5497 (0.5484)  loss_mask: 0.4500 (0.4556)  loss_objectness: 0.0185 (0.0221)  loss_rpn_box_reg: 0.0158 (0.0185)  time: 0.6432  data: 0.0115  max mem: 2645\n",
            "Epoch: [1]  [ 50/385]  eta: 0:03:36  lr: 0.005000  loss: 1.2241 (1.2857)  loss_classifier: 0.2345 (0.2584)  loss_box_reg: 0.5038 (0.5398)  loss_mask: 0.4281 (0.4495)  loss_objectness: 0.0157 (0.0200)  loss_rpn_box_reg: 0.0154 (0.0179)  time: 0.6416  data: 0.0108  max mem: 2645\n",
            "Epoch: [1]  [ 60/385]  eta: 0:03:29  lr: 0.005000  loss: 1.1269 (1.2709)  loss_classifier: 0.2118 (0.2536)  loss_box_reg: 0.5008 (0.5356)  loss_mask: 0.4001 (0.4438)  loss_objectness: 0.0140 (0.0201)  loss_rpn_box_reg: 0.0146 (0.0178)  time: 0.6390  data: 0.0124  max mem: 2645\n",
            "Epoch: [1]  [ 70/385]  eta: 0:03:22  lr: 0.005000  loss: 1.1415 (1.2510)  loss_classifier: 0.2045 (0.2465)  loss_box_reg: 0.5097 (0.5267)  loss_mask: 0.3981 (0.4397)  loss_objectness: 0.0179 (0.0204)  loss_rpn_box_reg: 0.0148 (0.0176)  time: 0.6332  data: 0.0129  max mem: 2645\n",
            "Epoch: [1]  [ 80/385]  eta: 0:03:15  lr: 0.005000  loss: 1.1485 (1.2410)  loss_classifier: 0.1991 (0.2437)  loss_box_reg: 0.5061 (0.5245)  loss_mask: 0.4001 (0.4365)  loss_objectness: 0.0129 (0.0192)  loss_rpn_box_reg: 0.0138 (0.0171)  time: 0.6292  data: 0.0127  max mem: 2645\n",
            "Epoch: [1]  [ 90/385]  eta: 0:03:08  lr: 0.005000  loss: 1.2027 (1.2407)  loss_classifier: 0.2169 (0.2432)  loss_box_reg: 0.5061 (0.5230)  loss_mask: 0.4267 (0.4384)  loss_objectness: 0.0093 (0.0187)  loss_rpn_box_reg: 0.0152 (0.0172)  time: 0.6277  data: 0.0121  max mem: 2645\n",
            "Epoch: [1]  [100/385]  eta: 0:03:01  lr: 0.005000  loss: 1.2505 (1.2393)  loss_classifier: 0.2225 (0.2425)  loss_box_reg: 0.5093 (0.5242)  loss_mask: 0.4267 (0.4371)  loss_objectness: 0.0093 (0.0183)  loss_rpn_box_reg: 0.0165 (0.0172)  time: 0.6291  data: 0.0122  max mem: 2645\n",
            "Epoch: [1]  [110/385]  eta: 0:02:54  lr: 0.005000  loss: 1.2370 (1.2335)  loss_classifier: 0.2204 (0.2413)  loss_box_reg: 0.5249 (0.5216)  loss_mask: 0.4238 (0.4362)  loss_objectness: 0.0066 (0.0172)  loss_rpn_box_reg: 0.0145 (0.0172)  time: 0.6261  data: 0.0125  max mem: 2645\n",
            "Epoch: [1]  [120/385]  eta: 0:02:48  lr: 0.005000  loss: 1.1539 (1.2308)  loss_classifier: 0.2243 (0.2416)  loss_box_reg: 0.4812 (0.5195)  loss_mask: 0.4010 (0.4347)  loss_objectness: 0.0072 (0.0179)  loss_rpn_box_reg: 0.0144 (0.0172)  time: 0.6215  data: 0.0127  max mem: 2645\n",
            "Epoch: [1]  [130/385]  eta: 0:02:41  lr: 0.005000  loss: 1.1278 (1.2224)  loss_classifier: 0.2087 (0.2382)  loss_box_reg: 0.4725 (0.5163)  loss_mask: 0.4010 (0.4333)  loss_objectness: 0.0104 (0.0174)  loss_rpn_box_reg: 0.0129 (0.0171)  time: 0.6247  data: 0.0132  max mem: 2645\n",
            "Epoch: [1]  [140/385]  eta: 0:02:35  lr: 0.005000  loss: 1.1307 (1.2230)  loss_classifier: 0.1957 (0.2373)  loss_box_reg: 0.5169 (0.5163)  loss_mask: 0.4191 (0.4339)  loss_objectness: 0.0098 (0.0184)  loss_rpn_box_reg: 0.0151 (0.0171)  time: 0.6216  data: 0.0115  max mem: 2645\n",
            "Epoch: [1]  [150/385]  eta: 0:02:28  lr: 0.005000  loss: 1.1961 (1.2198)  loss_classifier: 0.2028 (0.2352)  loss_box_reg: 0.5250 (0.5160)  loss_mask: 0.4231 (0.4331)  loss_objectness: 0.0154 (0.0183)  loss_rpn_box_reg: 0.0158 (0.0172)  time: 0.6234  data: 0.0118  max mem: 2645\n",
            "Epoch: [1]  [160/385]  eta: 0:02:22  lr: 0.005000  loss: 1.0990 (1.2126)  loss_classifier: 0.1725 (0.2315)  loss_box_reg: 0.4959 (0.5135)  loss_mask: 0.4231 (0.4328)  loss_objectness: 0.0099 (0.0178)  loss_rpn_box_reg: 0.0158 (0.0170)  time: 0.6248  data: 0.0119  max mem: 2645\n",
            "Epoch: [1]  [170/385]  eta: 0:02:16  lr: 0.005000  loss: 1.1234 (1.2090)  loss_classifier: 0.1725 (0.2308)  loss_box_reg: 0.5007 (0.5117)  loss_mask: 0.4170 (0.4320)  loss_objectness: 0.0096 (0.0174)  loss_rpn_box_reg: 0.0150 (0.0170)  time: 0.6297  data: 0.0130  max mem: 2645\n",
            "Epoch: [1]  [180/385]  eta: 0:02:09  lr: 0.005000  loss: 1.1704 (1.2113)  loss_classifier: 0.2178 (0.2312)  loss_box_reg: 0.5047 (0.5123)  loss_mask: 0.4014 (0.4310)  loss_objectness: 0.0100 (0.0192)  loss_rpn_box_reg: 0.0162 (0.0176)  time: 0.6334  data: 0.0121  max mem: 2645\n",
            "Epoch: [1]  [190/385]  eta: 0:02:03  lr: 0.005000  loss: 1.1438 (1.2087)  loss_classifier: 0.2170 (0.2306)  loss_box_reg: 0.4971 (0.5099)  loss_mask: 0.4171 (0.4313)  loss_objectness: 0.0167 (0.0194)  loss_rpn_box_reg: 0.0140 (0.0175)  time: 0.6293  data: 0.0123  max mem: 2645\n",
            "Epoch: [1]  [200/385]  eta: 0:01:56  lr: 0.005000  loss: 1.1364 (1.2091)  loss_classifier: 0.2205 (0.2315)  loss_box_reg: 0.4892 (0.5099)  loss_mask: 0.4215 (0.4309)  loss_objectness: 0.0189 (0.0193)  loss_rpn_box_reg: 0.0135 (0.0174)  time: 0.6293  data: 0.0139  max mem: 2645\n",
            "Epoch: [1]  [210/385]  eta: 0:01:50  lr: 0.005000  loss: 1.2120 (1.2113)  loss_classifier: 0.2471 (0.2320)  loss_box_reg: 0.5056 (0.5104)  loss_mask: 0.4345 (0.4323)  loss_objectness: 0.0138 (0.0194)  loss_rpn_box_reg: 0.0146 (0.0173)  time: 0.6346  data: 0.0138  max mem: 2645\n",
            "Epoch: [1]  [220/385]  eta: 0:01:44  lr: 0.005000  loss: 1.2698 (1.2112)  loss_classifier: 0.2381 (0.2318)  loss_box_reg: 0.5363 (0.5106)  loss_mask: 0.4345 (0.4322)  loss_objectness: 0.0164 (0.0194)  loss_rpn_box_reg: 0.0166 (0.0173)  time: 0.6319  data: 0.0127  max mem: 2645\n",
            "Epoch: [1]  [230/385]  eta: 0:01:38  lr: 0.005000  loss: 1.1738 (1.2076)  loss_classifier: 0.2263 (0.2314)  loss_box_reg: 0.5008 (0.5092)  loss_mask: 0.4287 (0.4309)  loss_objectness: 0.0119 (0.0190)  loss_rpn_box_reg: 0.0139 (0.0172)  time: 0.6295  data: 0.0122  max mem: 2645\n",
            "Epoch: [1]  [240/385]  eta: 0:01:31  lr: 0.005000  loss: 1.1594 (1.2070)  loss_classifier: 0.2310 (0.2313)  loss_box_reg: 0.5008 (0.5093)  loss_mask: 0.3986 (0.4305)  loss_objectness: 0.0098 (0.0187)  loss_rpn_box_reg: 0.0135 (0.0172)  time: 0.6297  data: 0.0124  max mem: 2645\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate the model\n",
        "\n",
        "# let's train it for X epochs\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # train for one epoch, printing every 10 iterations\n",
        "    train_one_epoch(\n",
        "        model, optimizer, data_loader, device, epoch, print_freq=10\n",
        "    )\n",
        "    # update the learning rate\n",
        "    lr_scheduler.step()\n",
        "    # test_loss  = evaluate_loss(model, data_loader_test, device=device)\n",
        "    # print(test_loss)\n",
        "    # evaluate on the test dataset\n",
        "    evaluate(model, data_loader_test, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "xeHb_-DwhxWt",
        "outputId": "2c447d85-d30c-4c76-b9ba-76036c96cf3c"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_d4e06656-ad84-46c2-a480-c5ed6c2ab4d7\", \"box_maskrcnn_model_v2.pt\", 176315009)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Save model\n",
        "\n",
        "torch.save(model.state_dict(), 'box_maskrcnn_model_v2.pt')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('box_maskrcnn_model_v2.pt') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLjPzBc2iDBl"
      },
      "outputs": [],
      "source": [
        "# pick one image from the test set\n",
        "img, _ = dataset_test[0]\n",
        "# put the model in evaluation mode\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    prediction = model([img.to(device)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wlfszr_jiZjC",
        "outputId": "7c58665d-ff36-45a0-d082-b6929a18197c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'boxes': tensor([[317.0796,  96.8237, 367.0044, 161.6824],\n",
              "          [296.1068, 190.7375, 339.8210, 244.6134],\n",
              "          [314.4531, 208.1520, 374.7933, 241.5902],\n",
              "          [330.7513, 212.6647, 390.9952, 245.9757],\n",
              "          [296.2657, 187.0650, 333.4860, 216.1329],\n",
              "          [305.8698, 199.5978, 354.2352, 240.7517],\n",
              "          [281.5683, 200.4684, 328.5360, 247.6907],\n",
              "          [275.2345, 243.8860, 332.1109, 282.9610],\n",
              "          [289.4790, 231.4758, 333.3951, 249.5166],\n",
              "          [356.9481, 214.6974, 396.3979, 246.9258],\n",
              "          [303.2405, 190.1718, 345.2505, 225.3317],\n",
              "          [292.1001, 235.5836, 334.4808, 258.2150],\n",
              "          [301.3796, 199.9965, 348.6612, 241.6226],\n",
              "          [303.9781, 199.0609, 327.7428, 242.8238],\n",
              "          [294.5355, 218.2314, 336.3816, 246.3315],\n",
              "          [298.4426, 214.5690, 320.0352, 246.0636],\n",
              "          [263.9703, 207.7230, 312.6088, 248.4113],\n",
              "          [294.2297, 227.2630, 331.6884, 243.0618],\n",
              "          [274.9230, 245.5584, 329.5908, 282.7603],\n",
              "          [315.5575, 209.2149, 371.0883, 242.3255]], device='cuda:0'),\n",
              "  'labels': tensor([4, 2, 3, 3, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 4, 2],\n",
              "         device='cuda:0'),\n",
              "  'scores': tensor([0.9995, 0.9507, 0.9327, 0.8061, 0.6610, 0.6468, 0.5602, 0.4251, 0.3237,\n",
              "          0.2556, 0.2062, 0.1977, 0.1395, 0.1192, 0.1135, 0.1056, 0.0949, 0.0542,\n",
              "          0.0531, 0.0509], device='cuda:0'),\n",
              "  'masks': tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            ...,\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              "  \n",
              "  \n",
              "          [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            ...,\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              "  \n",
              "  \n",
              "          [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            ...,\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              "  \n",
              "  \n",
              "          ...,\n",
              "  \n",
              "  \n",
              "          [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            ...,\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              "  \n",
              "  \n",
              "          [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            ...,\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              "  \n",
              "  \n",
              "          [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            ...,\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "            [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')}]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Printing the prediction shows that we have a list of dictionaries. \n",
        "# Each element of the list corresponds to a different image. \n",
        "# As we have a single image, there is a single dictionary in the list. \n",
        "# The dictionary contains the predictions for the image we passed. \n",
        "# In this case, we can see that it contains boxes, labels, masks and scores as fields.\n",
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxHtTzqQoq8C",
        "outputId": "a9517dcd-6c08-4263-c35d-0b8cab0f4d2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(prediction[0]['masks'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "5eK7P8-sipi-",
        "outputId": "a4c494a5-af57-4a36-9281-3ce829c5e5d1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAIAAAC6s0uzAAA0vElEQVR4nO3d2ZNk12Hn99+5W26VS+179d5AA2isBMBlBC7SkDQ1nhE1M3I4wvK8jB/mSa9+m5D/As+LI/ygcMh88dgSR2OFR5SooSiuIBsgAWJH7137npWZleu99/ih0I1Gs7u6srZb3fX9REVFoXDz1imSWV+eu5xrrLUCAACHy0l6AAAAHEcEGACABBBgAAASQIABAEgAAQYAIAEEGACABBBgAAASQIABAEgAAQYAIAEEGACABBBgAAASQIABAEgAAQYAIAEEGACABBBgAAASQIABAEgAAQYAIAEEGACABBBgAAASQIABAEgAAQYAIAEEGACABBBgAAASQIABAEgAAQYAIAEEGACABBBgAAASQIABAEgAAQYAIAEEGACABBBgAAASQIABAEgAAQYAIAEEGACABBBgAAASQIABAEgAAQYAIAEEGACABBBgAAASQIABAEgAAQYAIAEEGACABBBgAAASQIABAEgAAQYAIAEEGACABBBgAAASQIABAEgAAQYAIAEEGACABBBgAAASQIABAEgAAQYAIAEEGACABBBgAAASQIABAEgAAQYAIAFe0gNIxne+852kh4BDUZ1Tp570IHDcRXF8/dbcTy/95q33Pl4tV7p9eSaT+fznP/+tb31reHhYkso3FXf2f5SPmj/+kz9Negh7dUwDDACHxnWcsycnxoYHX33h6Z++8Zs33v5gs9Hc+csbjcaPfvSjmZmZr371q6+88oovmYMbKw4RAQaAw5DNpJ44M3X6xNjXvvS5//j/fv+ja9NRFO3wtVEUXb58eX1trdCTvXiy70DHiUPDOWAAOCTGmMD3T02O/rv/8Q+/8dqrE6NDrvPwP8KOY0qFngvnTn7u4rn+oGXi8BCGikPADBgADlsx3/Mvv/WVV198+q33Pv7bf/xF/QFHpEeG+p954vTk6FB/X3F8eLC/t3jI48SBIsAAkADf905Njo6PDEyNDf/Ff/mHpZW1MIqMjOe5QeB/7tknP//iM6OD/ZlMOvA9ZwcTZTxyCDAAJMb3vBcvPnH21MRb713+8MqNdDr11LlTz1046/ueJGO43OpxRoABIDFbiS3me778+Re+/PkXkh4ODhWHNQAASAABBgAgAQQYAIAEEGAAABJAgAEASAABBgAgAQQYAIAEEGAAABJAgAEASAABBgAgAQQYAIAEEGAAABJAgAEASAABBgAgAQQYAIAEEGAAABJAgAEASAABBgAgAQQYAIAEEGAAABJAgAEASAABBgAgAQQYAIAEEGAAABJAgAEASAABBgAgAQQYAIAEEGAAABJAgAEASAABBgAgAQQYAIAEEGAAABJAgAEASMAxDfClS5emp6fb7XbSAwEAHFNe0gNIxp/92Z8FQeD7/sjIyLlz586dOzc5Oen7vuu6rus6jmOMSXqMAIDH2TENcL1er9frkpaXl9955x1JxpjR0dGTJ0+eOnVqdHQ0l8sVCoV8Pp9Op5MeLADgMXRMA/zME6eX18qraxthFG19x1o7Nzc3Nzf3s5/9zHGc3t7eoaGhoaGhvr6+/v7+8fHxkZGRXC6X7LABAI+NYxrgf/vf//NGs9VsteaXVq/dnL1yc3Z2YTmKImtlrY3jeHV1dXV19YMPPnAcJ51O53K5bDZbKpUmJiYuXLgwNTWVz+clOY4jiePVAIBuGWtt0mNIwHf+w7+XtPW7x7G1No7ieHZ++crN2as3Z+YWVpqtdqPZajRbnTC8+4XGmK0zxMVi8dSpU88888zU1FShUMjlcul02nXdZH4fPEh1Tp160oMAsP/++E/+NOkh7NUxnQFv2Zq5uq6RHE86fWL89Ilx6ZUwilZWy7OLy3OLK6vrG+WN6uLK+ur6RrPVttZGUSRpa4r8xhtvbF3JdfLkyaGhoVKpNDAwsPWF7/tJ/34AgKPrWAf4QTzXHRnqHxnqf+miwija3GyUK7VKbbO8UZ1dXL58fWZ2YbneaG5t3Ol0pqenp6enJQVBUCgUSqVSLpcbGho6ceLE1iVdd8+MOV4NABABfijPdYuFnmKhR1Icx1EUd8IwiqL1jdq1W7PvX74xPbdY22x0wrDd6bTb7ZWVlZWVFUmO43i3jY+Pnzt37uzZsxMTE1u3P23d8kSMAeDYIsBdcBzHcRzf9yTle3JT48Nf+cKLktY3qtNzizdm5heX18qVWrlSLW/Uqpv1dru9tdZHpVL54IMPtvYwPDx84sSJqampoaGhnp6evr6+UqnEzU4AcNwQ4H3QW8z3FvPPXjhrra1t1lfLlbX1SrlSW1xZm11YmplfXitXtraM43h+fn5+fv711193XbdYLPb39/f19fX29g4PD588eZKbnQDgmCDA+8kYk+/J5XtyJydGrbXtTthqtZvtdr3RnJ5b/Pja9JUbMytrG7GN4yiOomhtbW1tbU2S4zhBEKTT6VQqVSqVTp069eyzz05NTW1dWc3KXADw+DnWtyEdmjv/IVurZqs1u7D88bVbN2cW1jYq9Xpzo7ZZbzSjKL7nValUanJy8umnn56cnNy6sKtQKGSzWW526gK3IQGPKW5Dwo7cmb8ao2wmfe7U5LlTk5KardbK2sbWzU5r5crS6vrc4sra+kYnjCS1Wq0rV65cuXJFUiaTGRwcHBsb6+vr6+vrGx4eHh0d7evr8zz+GwSARxJ/vpOUTqUmRocmRocktTthvdGo1uqNZmtpZf3ardkrN2fnFpY7YSRrG43GrVu3bt26JSkIglwu19PTk8lkRkdHT58+ffr06fHx8buPVHPIGgCOOAJ8VAS+F/j5UiEv6ezJyc+/9Ewcx3Fs5xaWr9ycuXJjZmZ+udVqN1vtZqu1vr6+vr4u6fLlyz/5yU+2bnmamJg4e/bs2bNnx8bGts4op9Np1gMBgKOJAB9FjmMcuXJd3V6f6+uvvRrF8fLq+uzC8uzCyspauVyprqxtrK5vNJqtKIo6nc7ly5cvX74syfO8wcHBiYmJ8fHx/v7+YrG49VQJbnYCgKODAD8yXMcZGewfGex/6aKiKKpuNsob1XK1trFRnV9avXJzdnZhabPelBSG4dbNTpcuXXJdN5/P9/X1FQqF3t7esbGxJ554YmuKnPQvBADHGgF+JLmuWyr0lG6vzxVGUacThmFUrtZuTM+99/H1W7OL1c16GEadTlgul8vlsiRjjOd5W6eQT5w48dxzz506dapYLHqet7Uy19bDnQAAh4AAP/IcxwkcJ/B9SYV8bmps+LVXX5BUqW7emlu8dmtuYWm1XK1tVGoblVqt3uh0Opubm0tLS5cuXZKUy+UmJyfPnDkzOjpaKpWKxWKpVOrp6eFmJwA4UAT4sXL3xc/FQs/FQs/FJ89Ya2v1xuraxspauVypLa2uzy0uzy2srKxvSNrc3Pzwww8//PBDSZlMZmBgYHBwsFgsbt31ND4+Pjg4yMwYAPYdAX78GWPyuWw+lz05ubU+V6fZbDdb7XqjOT2/dPnG9NUbM0sr67G1rVbrzpOdfN9Pp9OZTCadTm89TOLMmTNjY2NbC2JvPRc56d8MAB5hBPh4McakgiAVBEXJWntycvSfvPyslVqt9szC0uXr09dvzW9dWV3drNfr9Wq1KunWrVuvv/66pCAIxsbGzp49e+bMmcHBwUwm09PTk8vluNkJALpFgI+vrePVW5+zmfT5U1PnT01JarXaK+sbM/NLy2vl9Y3qylp5bnFlrVzpdMJWq3X9+vXr169///vf932/v79/bGxseHi4t7d36+v+/n5udgKAnSDAuFcqFYyPDI6PDErqdMJavVGpbtYbzZW18vXpuSs3Z+cWVtqdTqfTWVhYWFhYkOS6bi6XKxaL2Wy2r6/v5MmTFy5cGBsbuzMzZmUuALgHAcZ2fN/betiipDiOv/DSM1Ecx7GdX1q5cmPm8vWZmfmlZrPVanca9c1KpSLJGPPLX/7Sdd1sNnvmzJmLFy9OTU0VCoVUKpVKpYIg4OQxAIgAY+e2Lr/a+l/M6anx01PjX3/t1Ti2y6vrMwtLM/PLSytrG9XNtfLGWrlSb7Ta7fabb7755ptvSsrn8+Pj41NTU8PDw6VSqa+vr7+/v1AoEGMAxxYBxp44jhke7Bse7Hvp4pNRHFdr9fJGdb1SLW/UFpZXr0/Pzcwv1TYb1Wr1zs1O2Wy2VCr19vbm8/mRkZHJycmpqamhoSEOUwM4Vggw9o3rOFvrc53UaBzbMAzbnU67E1ZqmzdnFt77+NrNmYVKrR5F4eLi4tzcnKStRbi2Hh0xMTFx/vz5c+fODQ8Pu67reZ7neUyRATyuCDAOhOOYIPCDwJfUW8yfGB957dXnJVVr9Vtzi1dvzswtrmxUapXa5kZls1qpbGxsLC4ubh2vDoJgdHT0zJkzJ06c6O/vz+Vyvb29PT09rF8N4HFCgHHg7j62XMjnnnni9DNPnJZU22ysrJWXVtfLleryanl+aWVucXV1faPdbt+8efPmzZuSgiAolUqjo6N9fX29vb3Dw8MnT54cGBjgzmMAjzoCjMT05DI9ucyd9bkazVaj0ao3WzPzS1duzly9MbuwvBpF4cry8tLSkiTXdTOZzNb9TqdOnbp48eLk5GRPT8/Wylxbkv6dAGCnjLU26TEk4Dv/4d8nPQTc39b/IK21sbXtdmdmYenK9ZmrN2eX18rNZmuz3qw3W1EU3SlusVg8ffr0+fPnJycn8/l8NpvNZrPpdPqTk8fVOXXqCf9KAA7AH//JnyY9hL1iBoyj5c76XI7kZdxP1+dqd1bWyjPzS4sr6+sblbX1yvzSylq5ura2tra29sYbb0gqFAojIyNjY2MDAwODgwPnz53vCyyT4juc+Yx/uRAPNKPBZpzvKBWL/3SA5BBgPBpSgX/P+lzlSm2z3lhb37g5tzg7v7RRqW1UN69evbKyOF8o9Dxx5uT5saLcTNIDPypM3U3/aDj1y4E437H5jk1Hcb4TD7TC0Xo02oj7WvI/ezCMNgMHjADj0XPv+lxRHMVxHMfWWmu1dUbYdRzf94yNkx7sUeEsp/2reRM5bjmlcsrKSpJj5VrrWnk2LrajkUZ4qhaO1G2xY4NYfmyDWK4lxsBBIMB4tG2tz8Ul0Q/lVD1T/vQ+LrMV1dgolulIklPzvdlc6s0BSdaLo1KrPVKLJjfjwZbtb8f9bWUjcVc2sH8IMHAMxHI2Aqft7nBzEzrOSspdcdx3C9aPbF877m/H/e14sh6frNv+tna6JwAPRICBYyA0zsIuT4ebjmsWM85ixhqrVGxTke0J4zOb0VOVaKypVCwvpsfALhBg4PFnQse70bPXnVijpmuart3wndmM96MBBXE80Qif3Yin6vFEQ8FxvKcR2DUCDBwDkXGX0jvf3MrGeuD1a+bORVlt173W417rsT2d5r+7Fo839zhM4Fjhmgrg8eesB6bV3WHiSNHON7ap2LpMf4HuEGDg8bf348/bi0/UbT480B8BPH4IMHAgbLPZujbdWd+wUfL3IntX8we6/7i/rVQXM2YA4hwwcCCsDf7h9ea7H82lUk42HQz2ZyZG0hOjqcH+O+dPD+/REVbebNZ0s5pGd8efvdgWO/wtAbrFmwbYf+7sQu5nv8pUay1pTqo6jvFc47pO4KdHh7KnJ7MnJ1ND/cZzje87vmecAzwW5awHptndO32bK7B+m82Ftq/d5aAAEGBg37U7qdffMpt1TzohGWk2juN2bNWJG83aRrX24VVJxvOCwb7M1Hj2xJjfV0qPDXv53EFMi93ZrMIDnG3bQhgPtg5u/8DjigAD+8ydXfQ/vmbiWJIrTUpWmtO9k0obhq35pdb8UvmXb7m5TM+5UyPf/oZf2P+rpdyZrOkc4AzbZiJb6hzc/oHHFRdhAfuq3Q7e/dBZWbvzja0Gj23zZrM2qtU33np/7j/+dVjd3OdHdFu5yxlF3Z0A/uRRDTvZvbG2r33vk5QA7AABBvaPte7yWvDmuyb+NEhG2joWPbr9I/6srb5/Ze4v/ktYqe7jiEzVc6peV1dg7by+kuTaeKre9bAAEGBgf6V+8bZbrtzzTSO50oT0kMWorK19cLXyzsc22rdbepz1lKkc5MOiXBud3jzA/QOPLwIM7BtnaTX41bsP+reBdEIPeWxB3G6v/fiXrcWV/ToQ7awHTrWLAMeKu7sHKRfaAa7AAnaDAAP7JIzSP75kNrc7HjsgnZGCbbaQWosrt/6Pv2jNL9l4zyt4WDkbgakf4LWW0Zkaj0ICdocAA/vDzi44H101D565GsmRhqST0vZz0vby6uz/9df1m7N7bXDbcVdTXZ0A7lZ0vnZwOwcebwQY2B/+9Wl3feOhm201eOJhx6Ib0/MLf/V3zbnFvRyLNi1n148B3qF4jCcgAbtEgIF9YGqbqZuzbrijs6eO1JIKUu/tj4xkbn98wtrGzdmZ//M/tZZ2fz7YtFy3mwBb2Y66uKM3LraVjQ5ygg08zggwsGfWujML/uUbO9y8LoWSc9dH5q4Y56Tg9kd7aWXmO3/VWlzZ1ahkNj3nIC+BjkebNkj+URPAI4oAA3sWxalfvu3Udno3zpruvc7Y3PWRlvK3P3KSt7DUeufD3Y3Lncsc6AngeKwhnwADu8RSlMBeedNzwbsf7XDjirTzhTZSkvFcP5fdzbCs/GuF3bxwp7u3doA1sIDdYwYM7E27k/qH19Xe0anTWKr/1qLQ2/OGBoILZ3c3NPdmrqvtuzoBrFxkCx1OAAO7RoCBPfGv3PCv3dphhjrSald7Nybz8nNeb3EXAzMN1y1vf8vxnsSlNs9gAPaCAAO7Z+qN4K33t1984w4rzXe5f3doIP3C07sYmCR3PiN7UPNTK2t7OzGPAQb2gAADu2Wte3PO//DaNotv3K0jNbrav+vkvvyKk93ljbze1YLiA3sGg6N4sKUMV2ABu0eAgd1qd1JvvuPs+OFFv/1I4O0Ykzp/Ov3UOePschbrzma7Otvc1VMIFcTxVJ0TwMBeEGBgV6z15hb9bi5+7uqRBe5Ab+53v+QUenYxNElqOO5GcHD3INkgjse7m88DuAcBBnYltqkf/sI0d1RVKzWkcOc7d5z0sxeCU5PG2eU71F1LmcZBPSTByiqI7QAngIE9IcDAbviXr/sfXd3hBLMudbWWlVPMZ7/4onF3//Z0FzKm1sVd/la2q3PA8WiTPx7AHvEeArpmGs3g0m9Ma0dTQCutd7n/zOeedftK3Y/rU856yjS7mAHHiuNuzhjHp3gIErBXBBjokrXujRnv6s0dXvwcSw9/RtJd3P7e7MvP7m5on2gbpxyY+ADf3TyFENg7Agx0xzRaqV+955QrO9z+Rld7d53MK8+5vUVjdn/9lKl7zkpq59t3e/zZFrkDGNgHBBjohrXu3IL//uUd5rHW1bVXkjc8mHrqnPH3tEi7U/W7egqhpOjex0NsJz69KY8loIG9IsBAN6xN/exXzo6Xvqp2FWDXTT15xh8Z3O3gPvmpTjlwKge4CGU0WZdLgIG9IsBAF7zr0zt/8FGty8uv3GJP5pXn9jj9VWy8Gz2mmzWwumKNtcMt/nIAe8fbCNixZiv140s7f/BRTV2t7qj0Sxf3Ov2VFMm7mu/qFV1d/2yLHZuLWAML2DsCDOyUf23avz69w/TE0lo3O3dKheyrz+9iVPeyptsTwGE3h8ltf9v2dHVeG8D9EWBgRz558FFlp7ff3Opu7yb76vNuaTePHbyHu5oyrYNaA0tS3N8iwMC+IMDAjjirZe/KjR3e+9uUurpNxxsdSj93QXtY+urTXV3Jd3fguxvWWFvqKMVDkIB9QICBHYnzuWhixO7s2UTL6ua2Hs9NPX3OG+jby72/d7hLafldBLKrG5CUim1vhxPAwL7Y2/WWwLFhi/n6738tt9nwrt7cPkAVabObPftTY9lXXzCBv6fx3db82kLrpTV3PuN/XPCv5E3dl5WsHvRkpO6uwMqG8WhzX8YJgAADO2NMPNRf+zd/mP+z/9u7OfugrWKp0c3016RThW9/0+0v7ccQJSnua6u3HZ2otV9dUWic5XTwQTF4t9ds+M6mp46z62cUWlmbi+IRnkII7A8CDOyYMTbfU/9vvtLz53/pNO4/EWx3+eCj9PNP+ePD+3Lw+VNGMpKsXBtP1JsT9ebX5t0bPd6tnLucdpcy7lLaVH1ju/6h8UhTaZbgAPYHAQa6YUx4cqL98rOpn76pKLqnYFZa7GZnTqEn++rz2t/63per6EwtOlNTxzgbgbPhO+sp70aPcyNrlzzb/nQA282PHcXnqwc+VODYIMBAl1JB4xuvqROmLr2t8DMHm6Ouzv4ak774pDc6tM/T3+35Nh5oxQMt2Vr7uTV1HMUyy4F7M+fMZJyVlCn7ioyJjEKjyCg2n54/dmx0locgAfuGAANdMsbmsvU/+Kem3QnefOfueM50s/SV21tMP3fBSXfx2KL9ZCTfyo8k2Z5GeOr2md1I2vCdsm+WUk7ZN1XfbHpqOqbpWsfaAncAA/uGAAO7EgTN3/uSf/mGqXxyVLYqtXb+cmOCsyf9E+MHM7g9cKW+TtzX0en6J7P7UGq6puGahst9i8A+4v0E7Iox0VB/4/e+FKdTVrJSvZsHH5l0KvuFF5zUAT6zaN94Uk9kB9vxVIM7gIF9xAwY2C3HaX3hRVmb+bsfNTYb3V38/OyT/smJgxoYgEcBAQZ2yxj5XuuLL8bGNH7+K7NRsY2WdrBWpenJZr/40iEMEMBRRoCBvfH99hdf1PlTfa12XG9EK2ud+eVoeTXaqMWVqm3dXhP6rjCnLz7pjQwe6sXPAI4eAgzslfE8b2RQkrVW9rRiK2tlrbXWttpxpRqVq+HySufWfLi85o8N5b700n4tPAng0UWAgX1jjJExdy5tNJJSgVvo8SdGpfNJjgzA0cNV0AAAJIAAAwCQAAIMAEACCDAAAAkgwAAAJIAAAwCQAAIMAEACCDAAAAkgwAAAJIAAAwCQAJaiBB55VrbmNK6n5uaD1Q23VnE3A+sXo1x/WOzvFHNxJhele6JsSixADRwhBBh4xMSKQxOFJgoVzQUrH6dvvZ+9vuCvtZx2x4SRiSPFjoxjHU+ua13XGkeOY52U9QthrhDlilHuRGv0+fq5TJwOLH8EgGTw3gMeAVa2bcJ1t7ruVVb88uX09NX07Ly/Gpro043uerxhLBubKFR0z17m/dU7/5SywX+38ru/V3n5oAcP4L4IMHDUzfsrb+Uuz/kr88Hqgr9Sdet2d48S/uyr2uos+ev7MUAAu0GAgaPuemr+r0s/qbkN7a67D2CNLXvVhmllbGo/9wtgZ7gKGjjqam59023ub323rHnVDa+2//sFsAMEGDjqSmE+F6cPYs81p77pNA9izwAeigADR11fWMhH2YPYc9sJQxMexJ4BPBQBBo66bJxOxcFB7LltOm0CDCSEAANHXToO/IO5W7djws/cyATgEBFg4KhLWd+37kHsuW06HWbAQEIIMHDUpeLAO5gZsDXWyh7EngE8FAEGjrqDa6RvPe9g5tYAHooAA0fd1iLPB7HnIPYP6OwygIfivQccda0dnKl1JWMU3zVZ3sms2bceAQaSwnsPOALC0FQ3VW8om7G+L9eRMXKMjCPHid34oUeh/7en9Hu9+sFHuhao7KgWqRJqI1Q1UjtWaBVaRVaRVaejRllRTrGvbGQ8x96O9QEstQXgwQgwkChrzUY19ev3/Hc/im7NReMjtlRQyreeL9+1nq/AH/ac1wZaU3l1fIWeQl/tQEtDWhzRnRO4YymNZ/THz9+7+9iqEakeaTNSI1Y9VqWs+XfUGleroGa88fTom4Ob81HoR6EXR14UelHkRaH34ce1wM8OD/RHt79pY5dIA/uIAAMJsVaSu7Sa+eu/9z++rnYnktwbM/fZUPqGq9BT5ClyFHkKPV1+Qn/+b7U68Mk2Ew94noJjlPOU8zR451sFaeruTd639n1rTRy5ceze/uyMnGv6XrpUyMexE0deHLtR6HXaQdhJhZ0g7ASddvDeB41bt8Lnnnyp1czF0ad/TOzt6boxBBt4IAIM7Jm1cb3RiuMoio0xjuu6rmMcxzjGGGOMYxwjyVprY2utdW1sYutsVFO/eCv15jumUjPWbnOI2UheJC+SWp9+M7up3lWt9ktGWUd9/u6Hb4yMsY4TSp+eab5QlNSSNu76LSUZayVrrIy15qmXbRjawP+VtabdTDc2C1L0D/9Y/au/8ny35+VnvjoyMLn7YQGPOwIM7JWpVJ0//8sPNqpXytV6NtVTLOb7S+lcNkgHfirwU6kgnXIcp91qdZqtqNN5stka2Wx4V2+55crd+3GkeMc/NFfX+LSunpM1GknJP/gbGoyRZLc+b33H++TvR0NSOlMv9K5JWlrValmZVKsTtu6/IwCSCDCwd8FvPsxem/4d6Zz0frX+UbW+PDN/3y2Hpacdp2ht6rdmvEbypHY3P/epd/WTryhyNBroiNzMG4ZaWVEcK4w6YdhJejjAkUaAgb3yLt+QlJKmpBHpWenX0odS+/ZU0ZGK0vPSU1JPHO/Xu+78RzKxJJ3MyDsat/RXKqpWJSkMw05EgIHtEGBgb8LQXVrd+tJIKWlMGpNelN6QZiRfelp6Rsrf3ma/jM4p1VIYqNc/KkvqrK5+EuAoDuOIxzwA2yHAwJ44q+um3bk7q1tfj0nflBaljNS/s+6aLk8DG6upG/rgonpcOUfjcuNKRfW6JHmu73l7uDAMOAaOyP9vBh5V7vySad7/aqNAmpQGdjzrNV2+IY3V0+9KUsY9KvfntlrqdKStALsEGNgOAQb2xF1YMa2urp3aN8bq6XdkYvW4R+Wd3GopDCXJ83yfGTCwrSPytgUeTWHorm+Y/TvZ6XRzkthI/SvqW1He0xFZ8eLODNj3At9PJz0c4EgjwMDumc2GqdT2cYdOl+/J7KZOXj9CM+B2+64Ae0HSwwGOtCPytgUeQda6iyvu/FKCQ8jWdWZaKedIzICt/fQQtOt6nss1nsB2CDCwS2azkXr9185nV7M6ZEFHoxsKjsb7OIrUaHzytet4XIQFbO9ovHGBR461waW3g998sO8zz27fkylH/hGY/kqKIjWbn3ztup7LDBjYFgEGdin981+ZcP/Xmuj2mX8vvavzN/Z9FLtx9wzYI8DAwxBgYJc6Z09u8wijQ5PvKBM+fLNDcPcM2HN9x/DnBdgO7xBgl9rPPJH0ECTJScs5Gpcb3wmwMSbwUzwMGNgeAQZ2KS72HNCeuzp0GwzIKxzQQLrT6WhjQ5KMcQIvlfRwgKOOAAO75F+fOaA9d/W2zEwqNXhAA+lOu61yWZKMMb5PgIGHIMDALgVvvZf0ECTJzcg5GrELQ9Vq0u1D0EkPBzjquEwROFoq0i2pInWkUOpIkRRJHclI3mc/JN1a1lRZpaGEhy2p0/kkwI5xc5mjcVgcOMIIMLArxtT++NuZv/9p+seX9mV/sVSX3pN+LW1IW7c32dsfuv3Z3LlJycimFJW0elYfLeulUH2+Sp56ffV6n6yN5UiOkSO55pMv7nzzIFirOJYkz/V6C0fjsDhwhBFgYJdsId954nTq9bfM1vLHuxVJZema9Kb00GUtrRRL7UFVn9HqV7TxgmT0v89L859uY6Sso4Knkqeir4Kr0ZT6fRV9FT31+upxlXKUdpRylHKUc5U3blGB44auFzrOLu+u8n3lciqXFfjpniwzYOAhCDCwW8ZE/b3RyIA3Pf/wjR+gLL0vfSTNSzu5m7dd1MYrWv0dbT6hKHf/bay0GWuzrfkHPCbRlbKucq6yrrKu+jy9FI7+t5VXPa/j+m3f73h+y/NbftD2/HYqU/eDhue3fb/tBS3Pe+DaI56nnh6Vy+orDnEPEvBQBBjYPVvMR32lXQQ4lhrSu9Lb0qq0kxm042jjBc38K9VPKcp1uVzWZ0VSNVL1dkkda/zK8AvLT9/+99ZxIuPEjhMbJ3LdcOsLx4kdJ3a9TpBqBOl6kGoGqUahtFroW0qlN5uNXNRpPHn6xLOnXijl+3c/OODYIMDA7tlM2hYLtpsaRlJVuixdklZvn9ndhpFy0rh0oaD/9X9SdXxP6b2vWLbmNO/6holjT7EeMNW9e8jWGElW5pNvnx4ykmH6C+wEAQb2wJiov6TAV/vhk1grrUkfSx9Ks1L8sO1T0qg0Kk1IY1LVVWtvE9/7cq1TCHPj7Z1fM3X3CIy9+woxHYmnIgKPCgIM7Ek0OmTTKfPgAG+1aVN6T3pHWt7BAWcjnZAuSmNS/nbxspt66Zf6wdfvKuCduWgolaU1aUWqSA2pJXWkttSUWvJznue5W9vmMulsOl0c7Jm8MDRke3vDQi7O9IdcMwUcNgIM7Ek0MmBT91+LOZZaUlP6QHpbWtODDup+KpCGpJekk5L32YVy0k197fuaH9fiuNPOp4zMM2+ezlxLtduddidstzvtZqe21mg3wnQQZIJUyvfTQZD2g2w2PdTbO1AslfI9pXzec11jjHGMu+G4coyM2fdpNYAdIMDAnthCPs5lneW1eyJWla5LH0hXd3Z5c1oaky5Ip6X0/TYw0hMf6n/5n7X81Sdu/dFLKQXjA0Pp/qPxHAYA3SPAwF5FY0PejU/XhW5IV6R3pBmpuc3LbvOkU9J5aUrayeMdCk+/8lRz6v6nW6NIrbZptdXumE6odttUN52lVWetHPf3hhefsMMDO/2tABwwAgzsVeepc6mf/yq2CqUr0iVpQWo97FWO6/a7zvOd8Jy1rhTseGV2Z25Rpbz/wRVned00m3G7rVbb1Jum2TJhqNjK2k8+29hEsTqhwlCeZzbr7W9+WQ84YA7gkBFgYK8650+3eksznc7bcXw1iqM4jq11YhvHkawc1zHGMY5xtriO47q5Yv6JF55+ynF63/5Aa+V2GJkoslGkKFIYPeiU7Fahe777PfPdu376XRtsdy43DL2Pr3dee+VBZ6wBHDICDOyZ51b+6Pernc5EGI2GYRRuRTiOw9BKrutuRdd1XcdzXc/zfb841FfoKxljas9dcBaWbbujTsdsfe6EanfUapt222w2TL3hLiy7lZq539u1q1uQTXlDe1s1E8A+IsDAnjmO9+SZE7t6qS3mo2L+3u9GkcLQWVpNXfpNcHPGNFv78txQU2+aetNay+26wFFAgIEjI47NZt2p1b3LN1KX3nbnlhTHsnb7Wjo7WNNji7HWWV6NT4zvw1AB7BkBBpJn6g13dsGbnveu3fKu3nIaO7l6Wup+XSx3ZiH83LPdDg/AQSDAQBI+WcJRzvxS6q33vRszzsq6s1Y+6EPDzsyCOAQNHA0EGDhcUWxabdNo+G9/kPrVu85q2bTbJtrhUeS9cpZX77QfQLIIMHBYrHWvT3sz8/4HV/2Pr5vooQtT7khXk1nTaKq6qRIrPwPJI8DA4cn+5+/7N2f3d59bF2HtdFZrrbOyFhNg4AjYl7sbAOyIU28kPILYuvv9/wAA7A4BBg5P5/RUwiOIY3d6PuExAJBEgIHDFJ6aSHYARnLKFbXayQ4DgAgwcJiioYGDuATZ7WrrRtNZLx/AKAB0hwADh8cWehJ/FoLZbDiLq8mOAYAIMHB4jLGeF/cWEx5Fq2XKlWTHAEAEGDhUvh8P9Sc8hk5oqpuKD2npDwAPQoCBw2N9L+ovJTsGI5lqleuwgMQRYOAQeW5c3P9FMO77qOBtOMvrZjPpO5KBY48AA4fIcWwuY93uLlvef+WKdvzAJQAHhKUogUNlM2mbSZlafT/3KcVSeNc/bn1uSU2pKTWktuNM+/68Y0qlwnOvPj842McTkYBkEWDgUMU9OZvNaj8CbKWaVJM2pFvSnNSUWlLj9he+1OO5QbGQKuYHBvsmz5y4ePZEvlQwPI4QOAIIMHCo4kJPnM+5Syu73oOVNqUFaVa6Kc1KG9I91zQ7rlPsLY5OjY9Mjo5OjQ2ODafSKboLHCkEGDhUNpe12Yzt5jGCW4eUY2lNui5dk1ak6v266wf+8MTI6SfPDo0P9xTzhd5iNpfdz9ED2D8EGDhcgR8XcjJG9iGrUsZSR2pIy9I70mWpKkWfffhgkE6l0qlcT27i9OSZp88PjQ0HqcB1HeM4zHeBI44AA4fLmLivJNdVGD5ok3Vp8fbny9Lyb22QyqR7B3oHhgcnz56YPD1V7C+5iV9ZDaBLBBg4bOHEiA0889kAb53ZvSldkealZWnzniPMRoVScfzkxOiJ8b7BvmJfqXewz/N4CwOPKt69wGELz5ywuZxtdUJrO9auWXtZumLMimM6xnQcxzqOY0zKMelMJl/K54uFwbHhqXMnCsWCH/h+4HOEGXgMEGDg0Hle/fe/6q6sXWm2Pmq0mo2mHCefTg3lMplspqeYz5cKPYWebD53zwSX6AKPEwIMJKDz/FMdaUKaSHokAJLCUpQAACSAAAMAkAACDABAAggwAAAJIMAAACSAAAMAkAACDABAAggwAAAJIMAAACSAAAMAkAACDABAAggwAAAJIMAAACSAAAMAkAACDABAAggwAAAJIMAAACSAAAMAkAACDABAAggwAAAJIMAAACSAAAMAkAACDABAAggwAAAJIMAAACSAAAMAkAACDABAAggwAAAJIMAAACSAAAMAkAACDABAAggwAAAJIMAAACSAAAMAkAACDABAAggwAAAJIMAAACSAAAMAkAACDABAAggwAAAJIMAAACSAAAMAkAACDABAAggwAAAJ8JIeAIDHhLVWcWzDSJIJfGNM0iMCjjQCDGD3rLVxoxlu1qNaPazVW4vL9Y9v2Cga+mdfy5wYNw7H2IAHIsAAumOtDSu19vJqe2m1vVburFc6a+udlXJYrd3ZZuG73xv+F1/Pnp6kwcCDEGAAD2OtrLVxXP3w6ubH11vzS9FmI2o04nozbrXv+4rmzMLy3/xw4t/8Szef41g0cF8EGMBDmHoz9cOfT//irZVa3Vorax/+GmvrV2+W33yn/7VX5LoHP0bg0cPRIQDbimP/42vpn7wxVan5cbyj+t62+vc/rbz9QRxGBzc64NFFgAE8mLXORjX9w9edRjMtTXT5JyParC//zQ8b127ZbrINHBMEGMADmY1q7jvfdW/Nbv3jsDQpdXVAub28Vr70drRZp8HAPQgwgAdodzI/+Ll3Y9ZYSTKSK41IxS53U3nr/bUfX7LtzgEMEXiEEWAA9xPH/pUb/rsfmTi++9u+NCYF3ezJdsLVf/h5+Zdv7+8AgUcdAQbwW6x1p+ez/+lvnbXyb//LojTZ7f7anfWfvtFaWuVANHAHAQZwL9NqZ//ye87y2oNu4B2QSl3us7W0uvw3P+ysb9BgYAsBBvBZYRi8/mtvduFB9TWSJ01J+a52G8fV33yw8vc/tZ1w72MEHgMEGMBt1iqMgjfeyfzgZ4q2u3nXSHlpSvK72n0Ub7zxm/rNWSbBgAgwgE9ZBb9+L/ufv28qtYeuHmmkkjTQ7U9odxa/+73W4oqNaTCOOwIM4BPORiXzNz90Gs0drt1spEmpX+pqrefWwtLCX/xNe3l1N0MEHiMEGIAkqd1O/+Bn973seRu+dKLbk8FWjRvTld98GHMyGMcbAQYgNVuZv/1x6hdvdfs6I2WkoS6f62LDaP3Hv6xfZ4lKHGsEGDj2Yut/dC3181+ZdmcXDw400qA01OWrwkpt/e9+LPqLY4wAA8edqVTTP7nk1Bu73oMrjUvpnW2cktJS2vMKF851d/YYeLzwPGDgWDOb9dz/8/95V27ucT+BdEK6Kj3ovG7u9heOZKTsi0/3vPr8Hn8o8EgjwMAxFobp//oz/8NrZj/OxfZLkXRT6tz1xKTsXRvcme56Q/25V553chljmALj+CLAwHEVx9616eCdj8y2a27skJGMNCBtSBUp9eAtnXxP4euvBScnqC+OOQIMHEvWugvL2b/+e2dlbd92KdWkcNv6mnSq9O2vZ567YNyuHisMPIYIMHAsdcLsd7/nTs/v1yTUShVpWttd1+z0ZEvf/gb1BbYQYOD4CaPUm+9412f28RBwRXrIdVyOk3n+qfTT56kvsIXbkIBjJoqCdz5Mf/8n2z9uoVvLD9vAGx7Iff5FJ73N8WngeGEGDBwn1roLy+nv/chZK+/X9DeWlqTtbyJ2+3v7/oc/8EeH9+lnAo8DAgwcJ+1O6me/cheX9/HU75K0tM0WxvjjI73/+lv+2DCXPQN34xA0cGy0O+kf/TJ16e19zODi9vWV3FKh+K2v+JOj1Be4BwEGjod2J/2jX6R/8DO1O/u1SyuVt9/CcdJPn0+dP2Uc/tQA9+IQNHAMWOt/fD39j78wO37W70OF0ozU3mYLx6TOnSx888vG4+8McB+8MYBjoN0Jfv2eU93cr/1F0qxU2WYLx0lfOFv6w286ucx+/VDgMUOAgcefabf99z7er71ZaXr7+kr+2HDhm192+4qc+gUehBMzwDHgedH4yH49ezeUattuYFJB9nMX/fER6gtsgwADjz+bTjW+/jvxQN/ed9WUrkvxNlt4bu7V53NfeNE41BfYDgEGjgFjwtOT7ecuWG9Py0C2pGmpuc0WntvzxZcK3/yykwr28oOA44AAA8eD7zd/5+Xw5MSuD0SH0rXtV7xy3Z4vvJT/xmsmk97tDwGOEQIMHBe2mK//wTfsbut4Xdr+DuJgYiT/u190shlO/QI7QYCBY8OYaHSw9cWXdnEguvKw+pp0qufLn3dLBeoL7BABBo4Tx2n9k891njy78wPRVqpJM1L44G1MKij+s69lLj6xDyMEjg0CDBwnxsSlQuvV5+NSYYcNrkvXt62vk88V//nv5V59QXu7wgs4bggwcMwY03nyTOtLn9PO1me+JW2XatfNf/ULuVeeN77HwWegKwQYOH58r/Wll6KRwe0nwVZa3nbuK8kfG8p94UXjs6Ye0DUCDBxHNpOuf/sbttDzwA2kVWlh2+mv21ssffsbJp06iBECjz0CDBxLxoSnJpqvvWLv96iirfrObVtfb2Sw949+Pzg5wZFnYHcIMHBceV772Qvh6Ul7v4AubPtSf2K09C/+KQ/6BfaCMzfA8RUP9DW++eWeuUXV6ncqHEuz913t2RjjuW5fKffyc5kXn3ZLBeoL7AUBBo4xx4SnJlsvP5f+x18ojiVF0py0fvc2rusWcm6xEJyayL540R8fkZEkjjwDe0SAgePNmOZXv+AuLgfvX7F319d1gskxf2zYG+zzR4f8yTE3l0l2pMBjhgADx53N51pf+px3a161zbIxbqmQee7JzDNPuKWCk+8xgc9kFzgIBBg49ozpnDtV/8Zr1bnFwc9d9CbHjOvIcegucKAIMAAp8Nu/8zL38wKHiYsYAQBIAAEGACABBBgAgAQQYAAAEkCAAQBIAAEGACABBBgAgAQQYAAAEkCAAQBIAAEGACABBBgAgAQQYAAAEkCAAQBIAAEGACABBBgAgAQQYAAAEkCAAQBIAAEGACABBBgAgAQQYAAAEkCAAQBIAAEGACABBBgAgAQQYAAAEkCAAQBIAAEGACABBBgAgAQQYAAAEkCAAQBIAAEGACABBBgAgAQQYAAAEkCAAQBIAAEGACABBBgAgAQQYAAAEkCAAQBIAAEGACABBBgAgAQQYAAAEkCAAQBIAAEGACABBBgAgAQQYAAAEkCAAQBIAAEGACABBBgAgAQQYAAAEkCAAQBIAAEGACABBBgAgAQQYAAAEmCstUmPAQCAY4cZMAAACSDAAAAkgAADAJAAAgwAQAIIMAAACSDAAAAkgAADAJAAAgwAQAIIMAAACSDAAAAkgAADAJAAAgwAQAIIMAAACSDAAAAkgAADAJAAAgwAQAIIMAAACSDAAAAkgAADAJAAAgwAQAIIMAAACSDAAAAkgAADAJAAAgwAQAIIMAAACSDAAAAkgAADAJAAAgwAQAIIMAAACSDAAAAkgAADAJAAAgwAQAIIMAAACSDAAAAkgAADAJAAAgwAQAIIMAAACSDAAAAkgAADAJAAAgwAQAIIMAAACSDAAAAkgAADAJAAAgwAQAIIMAAACSDAAAAkgAADAJAAAgwAQAIIMAAACSDAAAAkgAADAJAAAgwAQAL+fx7CkvliAmSuAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=640x480 at 0x7F04409773D0>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Image.fromarray(img.mul(255).permute(1, 2, 0).byte().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "9wwEvvubisgU",
        "outputId": "f70fa13e-c75f-4bfc-d3ee-efda8419acec"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAAAAAAQuoM4AAAG0UlEQVR4nO3cTW4kSXIGUDPziEiSPQXtdQZtdQFt5v7H0ELTPfVDZmaEu88iWdUl9QhaJCFKw/eQBDMJLpzAB3PzH0YEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD8/5TvPYB/GP/8b/+6raNHZmVEVWZlxuwj5n4d0Y+j9z7265x9P3q/7td9P67Xy3697r1fL+O9/4D3sbz3AP5hfPqXP69rHxF1C2BlVcbsPeJymbPve+/Hcb2OcVz343g579fz88v5+dvz8/NxPO8CyF3y9NjaMjKzMrOyMisixozYHmb0vY9xHMfR+7H32V/OR//25fn8/Nvnpa7Xa733+N+JAL6ZOSrmjKxWVZWVmRExI6KtEf045jj2MY9j9Jlxvhz96+fn69dtWddvzy8ftRcSwLdS62NbjiOrVWZmi1sAIyJaRGTWnFVz9t7HbLmuR2/t4WWZ2WbmswrIfeYYNbNVVXudhn+s8LLNiMg5okaPOeaMiKwR0Z7ieX2acSwqIPfJqqqYkRm3/N0ila9fFTkrc7ZeVbPliKONsfT4dFTs+6YCcqdqrWV8b/9eC+CMiMiZETXnjJiVkTlajpG5nrKPh4freV2bCsidsipbey1++brFegvha7oyYsxZI6uyamRG5VqZrfKj5k8A30xmZs35Y9L9L5F6/UnOzGqjRda+R+xH/6XPcX7WA3KnXLZWGfnH8GXOiIgZM2vOHhGVcUvssta5rafTadUDcq9bqn7E7xa739/mvE3KmRkVbYyqmjPaui6tPmoBFMC3M0dk5MyYP1q++Xd+7bYhmGNmxRzR9uPYHx/Xj5pAAXwrc/ScP8Xo1vG9pvCnahiZFRVLVKsatc/Zj5fnkymYe8055/yfK1lmRuZcerS197mc1qqPuwwWwLcy9+v8qe7FfxfFnFlRGVlLayOPpY7e+y/tf3Ww/3cI4NuZY2RW/KeJ+LUNnBExX9/f1ioVc7YYo5ZtaW2xEc2dxuX5FDMib93cH1Yg3z9mREZm1IzIXrH20+nhcRNA7jP2c+SM2WZm/rEMztcSmPOWv1sSc8Tsp8eni0UI95rj2CNmVGTVzJ92o+fPCfzpiC4zM7O1tmxOQrhT//rr07gu26ni+5Hw9wzOn16/5+92QDKr2uoyAneb47jkus7ZopaZVZXf5+F5W4P8FMDb99tVmWxtcxTHvcbl6zGWdT8q6rRVtfZ6JzBfA/h7V/gjg7eLqdVa+6j5E8A301++9NFqe6hoR29tWasyI2N+r4Dz+42YiIiYr2ckmdUWUzD3Gucv/Yi5nZZc931dttFaVURGjhEZc1Z+v5EVEd8n4Iistj6YgrnT8dd/Pz3MWE8ttn/6tJ0eHtalVc3I7D0rRla91sSIH5cDR1Ru++V9h/6eBPCtjMuX/TiO5bS0h4rtcsxjWZaKyOo9MmdWtZn1ukc4Z8acc4zRx2yb2zDc6fj6l9NDH8tp3Y7s22nft2XbaszWrtdacuayLEtVzYq4rYxfA3j068tHfTKHAL6Z8fLXbYu5nrfT3q+n0/m8bdtD9bGs50utFbmu29aqtYqMOeeMOeYc/dj36/X4e1cHPwIBfCvj8u2yZC3LdrlcXh4ezufTw3auPtb1fKmlVS3rw7EsrVXFnGPMGH3G3PfL+eW8CyD36S+fW1uXtlxP+/n0y7h+e3za1hyztculLUtb1vXobVmWlvPoY/Tee9S8XC+XX3/9j+t7j/+dCOCbGX2OsVct56Wtz99aPT5tLcesulxyabUs69PT6bSuyzKv+3GMeey1xuXaj89fz3pA7jP7XrVHtYxqy7a2tqxLy2O0dr3U2mpZtk+fluXhca257/sRsV/bY768HMeXL7/t7z3+dyKAb2XOEXOOqtmjVdXtIVkxRqt9r6Wq2vKnP1U9PC059+M4Mvt1eayXcz9eXn473nv870QA38p4+Zw5ZuTst3/OvD0qNWbm6FmRkXU6ZS5bZRyj98oxaqvrMcdx/OWj9oAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwIfwNHamrdyZdIXcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=640x480 at 0x7F0440971280>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Image.fromarray(prediction[0]['masks'][4, 0].mul(255).byte().cpu().numpy())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bf34de56443b4789b9555e98e8b1d901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71431459ca2b454bad1190da73ddc880",
              "IPY_MODEL_5277f085a2b9429e8bcc49cb06ce4e98",
              "IPY_MODEL_cbc6c45bcf024c6b8f16f0e70aecf854"
            ],
            "layout": "IPY_MODEL_3ff958a1c9a04558b6be01c6561bac80"
          }
        },
        "71431459ca2b454bad1190da73ddc880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ea50af33f14f0e89d067a097a71a74",
            "placeholder": "​",
            "style": "IPY_MODEL_34a62493ef564424ba1e3bce171254d2",
            "value": "100%"
          }
        },
        "5277f085a2b9429e8bcc49cb06ce4e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a92c7bda8eeb4ceb9499934a35964387",
            "max": 178090079,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_175c5bd2b7424c73a73a29d2b3a0ad25",
            "value": 178090079
          }
        },
        "cbc6c45bcf024c6b8f16f0e70aecf854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a86dec2a02848de9ff2992a737770fd",
            "placeholder": "​",
            "style": "IPY_MODEL_168a34af1cc9422e99cb44da3640746c",
            "value": " 170M/170M [00:00&lt;00:00, 224MB/s]"
          }
        },
        "3ff958a1c9a04558b6be01c6561bac80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6ea50af33f14f0e89d067a097a71a74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34a62493ef564424ba1e3bce171254d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a92c7bda8eeb4ceb9499934a35964387": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "175c5bd2b7424c73a73a29d2b3a0ad25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a86dec2a02848de9ff2992a737770fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "168a34af1cc9422e99cb44da3640746c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}